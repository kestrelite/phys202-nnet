{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Neural Networks\n",
    "\n",
    "Neural networks are a method for automatic decision-making and classification, more commonly known as weak AI. The idea developed out of synaptic connections in the brain, which output signals based on the magnitude of the incoming signals. The stronger the incoming signals, the greater the chance the neuron will activate.\n",
    "\n",
    "In neural networks, neurons are represented by nodes, which are grouped into layers. Simple neural networks are split into three parts:\n",
    "\n",
    " - The **input layer**, which accepts inputs from the \"outside world\" - for instance, an image of a digit. \n",
    " - The **hidden layer**, which can really be thought of as a processing layer, where computations happen.\n",
    " - The **output layer**, which returns processed information.\n",
    " \n",
    "![Image courtesy the OpenCV project](http://docs.opencv.org/_images/mlp.png)\n",
    "\n",
    "In this image, courtesy the OpenCV project, there are three input nodes, five hidden layer nodes, and two output nodes. Each node in a successive layer receives values from all of the nodes in the layer before it. Let's create this network now, as a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nnet_core import *\n",
    "from transfer_funcs import linear_transfer, linear_transfer_deriv\n",
    "from matplotlib.pylab import cm\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "# This will start with randomized weights and biases\n",
    "weights, biases = nnet_setup([3, 5, 2], transferp=linear_transfer, transfer_derivp=linear_transfer_deriv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A synapse in the brain can be emulated as a device with a _threshold_ and an _output_. If the inputs to the synapse are greater than the threshold, then the output is triggered. However, unlike the synapses in the brain, which must either output a 1 or 0, neural networks allow for dyanmic input and dyanmic output. To do this, nodes have two values associated with them: a weight $w$ and a bias $b$.\n",
    "\n",
    "In order for a node to transmit a positive value, its input has to exceed its bias. This gives us the formula $x*w-b$ for a single connection. We can then write all incoming connections to a single node as follows:\n",
    "\n",
    "Let $w_{ij}$ be the weight from node $i$ to the node $j$ between two layers, and let $b_j$ be the bias of the node $j$ in the second layer. (Note that biases are specific to the _node_, not the _connection_.) Then, the total information that goes to a single node from the previous layer is: $$\\sum_i x_i * w_{ij} - b_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural networks as matrix multiplication**\n",
    "\n",
    "You might notice something in the previous notation: $x_i$ and $b_j$ form column vectors, and $w_{ij}$ can form a matrix. This does hold true; consequently, we can write the computation between layers as such:\n",
    "\n",
    "$$\\left(\\begin{matrix}w_{11} & \\cdots & w_{1i} \\\\ \\vdots & & \\vdots \\\\ w_{j1} & \\cdots & w_{ij} \\end{matrix}\\right) \\left(\\begin{matrix}x_1 \\\\ \\vdots \\\\ x_i \\end{matrix}\\right) - \\left(\\begin{matrix}b_1 \\\\ \\vdots \\\\ b_i \\end{matrix}\\right)$$\n",
    "\n",
    "This makes it very easy to compute, and that is how the following function is implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93912544],\n",
       "       [-7.63971805]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet_prop(weights, biases, np.rot90([[1, 1, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Giving it something to learn**\n",
    "\n",
    "As a demonstration, let's say we wanted to teach it to output higher on the first node if the first two numbers are higher than the third, and output higher on the second node if they aren't.\n",
    "\n",
    "First, we need to generate some data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset_mgmt import *\n",
    "import random as rand\n",
    "\n",
    "training_data_count = 150\n",
    "\n",
    "training_data = []\n",
    "test_data = []\n",
    "for i in range(0, training_data_count * 2):\n",
    "    inp = [rand.randint(1, 10), rand.randint(1, 10), rand.randint(1, 10)]\n",
    "    if(inp[2] == sorted(inp)[::-1][2]): training_data.append(([inp], 1))\n",
    "    else: training_data.append(([inp], 0))\n",
    "test_data = training_data[training_data_count:]\n",
    "training_data = split_to_batch(training_data[:training_data_count], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did I use 0 and 1 instead of column vectors? Part of that is a limitation of the way I wrote this library, as I wrote it with digit recognition in mind. They don't have to be, however, the utility functions I have do a handy job of turning those into target vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 1.]] \n",
      "\n",
      "[[ 1.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(create_tgt_vec(0, length=2), \"\\n\")\n",
    "print(create_tgt_vec(1, length=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic gradient descent and backpropagation**\n",
    "\n",
    "Now it's time to see how the network actually learns something. First, it's helpful to see what it does. The code below makes a copy of the neural network we created earlier, then trains it 50 times against the training data we created.\n",
    "\n",
    "_Note:_ Some networks will train better than others. If you get an uninteresting graph, go up to the top and create a new random network to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting accuracy: 38.0%\n",
      "Ending accuracy: 79.5%\n"
     ]
    }
   ],
   "source": [
    "# Make a copy for playing with\n",
    "wts, bias = weights, biases\n",
    "print(\"Starting accuracy: \" + str(100 * nnet_evaluate_single(wts, bias, test_data)[2]) + \"%\")\n",
    "\n",
    "iteration = []\n",
    "evaluation = []\n",
    "\n",
    "for i in range(0, 20):\n",
    "    iteration.append(i+1)\n",
    "    evaluation.append(nnet_evaluate_single(wts, bias, test_data)[2] * 100)\n",
    "    wts, bias = nnet_SGD(training_data, wts, bias, 0.0010, outp_length=2)\n",
    "    \n",
    "print(\"Ending accuracy: \" + str(100 * nnet_evaluate_single(wts, bias, test_data)[2]) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEPCAYAAACp/QjLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWRmHg5mZlXE4mJlZmf8P7X7Sau+niXcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fd8aff710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(iteration, evaluation)\n",
    "plt.ylim([min(evaluation), 100]); plt.xlim([1, max(iteration)])\n",
    "plt.xlabel(\"Training epoch number\")\n",
    "plt.ylabel(\"Percent accuracy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand what's happening, recall that the gradient of a vector always points in the direction of greatest decrease. Neural networks (ab)use this property to minimize the error of the outputs of the network. This is, in truth, the only fundamental principle at work here. We can adjust the parameters of the network to move in the direction that minimizes error. But how fast do we move? \n",
    "\n",
    "To answer that, the network uses a rate of movement, heretofore called the _learning rate_, represented by $\\eta$. Let's call the error a _cost function_ with respect to an input vector $\\vec{x}$. Then, for each $w_{ij}$, we can compute the derivative of the cost: $$\\frac{dC(\\vec{x})}{dw_{ij}}$$\n",
    "\n",
    "This represents how quickly the error changes with respect to the weight. All in all, we're setting up a differential equation. $$w_{ij}' = w_{ij} - \\eta \\frac{dC(\\vec{x})}{dw_{ij}}$$\n",
    "\n",
    "Then, we can do the same thing for biases. What's the end result? A movement like this:\n",
    "\n",
    "![](http://blog.datumbox.com/wp-content/uploads/2013/10/gradient-descent.png)\n",
    "\n",
    "(Courtesy datumbox)\n",
    "\n",
    "However, notice how this network seems to reach a maximum effectiveness? Also notice how the gradients have different minima?\n",
    "\n",
    "This is one of the problems with neural networks. There may be an absolute minimum of the network, but you won't be able to get there with stochastic gradient descent. Instead, we need a different tools to get us to higher accuracy. There are a number of these, which are better saved for a different overview."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
