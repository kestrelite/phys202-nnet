{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Monte Carlo Search Methods\n",
    "\n",
    "In order to improve training times, a Monte Carlo search was executed over the neural network's parameter space to find optimal parameters. This method cut the computation time in half in comparison to manual tuning, and resulted in equal or better output. For more information on what this method does, see [this notebook](NNet_MonteCarlo.ipynb).\n",
    "\n",
    "The following code generates data for a Monte Carlo search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, math, time, pickle, os;\n",
    "from nnet_core import *;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only run this cell to destroy active data in memory\n",
    "# First, set 'reset' to True to confirm\n",
    "\n",
    "reset = False; assert(reset)\n",
    "network_qtys_lst = []\n",
    "network_keep_lst = []\n",
    "network_eta_lst = []\n",
    "network_decay_lst = []\n",
    "network_firstlayer_lst = []\n",
    "network_secondlayer_lst = []\n",
    "network_epochs_lst = []\n",
    "network_setsize_lst = []\n",
    "network_batchsize_lst = []\n",
    "network_effectiveness_lst = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of this is hard-coded, and consequently, you may have to look through this yourself.\n",
    "\n",
    "The search space is: \n",
    "\n",
    "$$\\begin{array}{r|l|l|l} \n",
    "\\textbf{Parameter} & \\textbf{Min} & \\textbf{Max} & \\textbf{Step} \\\\\n",
    "\\hline \\mbox{Network Quantity} & 1 & 15 & 1 \\\\\n",
    "\\hline \\mbox{Network Keep Qty} & 1 & \\uparrow & 1 \\\\\n",
    "\\hline \\mbox{Learning Rate} & 0.5 & 1.5 & 0.1 \\\\\n",
    "\\hline \\mbox{Weight Decay Rate} & 0 & 0.001 & 0.0001 \\\\\n",
    "\\hline \\mbox{First Layer Nodes} & 5 & 30 & 1 \\\\\n",
    "\\hline \\mbox{Training Epochs} & 1 & 15 & 1 \\\\\n",
    "\\hline \\mbox{Training Set Size} & 100 & 1000 & 1 \\\\\n",
    "\\hline \\mbox{Training Batch Size} & 1 & 10 & 1 \n",
    "\\end{array}$$\n",
    "\n",
    "The following code creates and trains 200 sets of neural networks (an average of 1500 neural networks per dataset). **The following code takes approximately 2.5 hours to run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_to_generate = 200\n",
    "# Define a rigid test set up front of 500 elements\n",
    "_, test_set = load_data(400, 2, 500)\n",
    "\n",
    "start_time = time.time()\n",
    "time_elapsed_secs = lambda: time.time() - start_time\n",
    "\n",
    "i = 0\n",
    "while i < num_to_generate: \n",
    "    # Create random parameters in search space\n",
    "    networkQty = random.randint(1, 15);\n",
    "    networkKeep = random.randint(1, networkQty);\n",
    "    networkEta = 0.1 * float(random.randint(5, 15));\n",
    "    networkDecay = 0.0001 * float(random.randint(0, 10));\n",
    "    firstLayer = random.randint(5, 30);\n",
    "    secondLayer = 0;\n",
    "    epochs = random.randint(1, 15);\n",
    "    setSize = random.randint(100, 1000);\n",
    "    batchSize = random.randint(1, 10);\n",
    "    \n",
    "    netw = []\n",
    "    try:\n",
    "        # Create a new trained network with these starting parameters\n",
    "        # The 500 comes from above; the test set size is fixed, so we don't\n",
    "        # want to mix training data with test data\n",
    "        netw = nnet_train_new(networkQty, networkKeep, networkEta, networkDecay, \n",
    "                              firstLayer, secondLayer, epochs, setSize, batchSize, 500)\n",
    "    except:\n",
    "        # There is an undiagnosed error somewhere in the network that intermittently pops up.\n",
    "        # Ignore it if it happens and continue.\n",
    "        print(\"Encountered an unknown error training last network.\")\n",
    "        print(networkQty, networkKeep, networkEta, networkDecay, firstLayer, secondLayer, epochs, setSize, batchSize)\n",
    "        print(\"Aborting and restarting iteration.\")\n",
    "        continue\n",
    "    \n",
    "    network_qtys_lst.append(networkQty)\n",
    "    network_keep_lst.append(networkKeep)\n",
    "    network_eta_lst.append(networkEta)\n",
    "    network_decay_lst.append(networkDecay)\n",
    "    network_firstlayer_lst.append(firstLayer)\n",
    "    network_secondlayer_lst.append(secondLayer)\n",
    "    network_epochs_lst.append(epochs)\n",
    "    network_setsize_lst.append(setSize)\n",
    "    network_batchsize_lst.append(batchSize)\n",
    "    network_effectiveness_lst.append(nnet_evaluate_multiple(netw, test_set)[2])\n",
    "\n",
    "    # Estimate the time remaining\n",
    "    time_remaining = (time_elapsed_secs() / float(i + 1)) * float(num_to_generate - (i + 1))\n",
    "    time_remaining = time_remaining / 60\n",
    "    print(\"Completion: \" + str(int((float(i+1) / float(num_to_generate)) * 100.0)) +\"%; \" \n",
    "          + str(float(int(time_remaining*100))/100.0) + \" mins left.\")\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell simply verifies that the data is recorded correctly, and writes it out to `filename`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"testoutput.json\"\n",
    "\n",
    "output_data = {\"Net Quantity\":network_qtys_lst,\n",
    "              \"Net Keep Qty\":network_keep_lst,\n",
    "              \"Learning Rate\":network_eta_lst, \n",
    "              \"Weight Decay Rate\":network_decay_lst,\n",
    "              \"First Layer Nodes\":network_firstlayer_lst,\n",
    "              \"Second Layer Nodes\":network_secondlayer_lst,\n",
    "              \"Learning Epochs\":network_epochs_lst,\n",
    "              \"Training Set Size\":network_setsize_lst,\n",
    "              \"Training Batch Size\":network_batchsize_lst,\n",
    "              \"Effectiveness\":network_effectiveness_lst}\n",
    "output_data_backup = output_data\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "\n",
    "file = open(filename, 'ab+')\n",
    "pickle.dump(output_data, file)\n",
    "file.close()\n",
    "\n",
    "file = open(filename, 'rb')\n",
    "tmp = pickle.load(file)\n",
    "print(tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
