{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "import random, math, time, pickle, os;\n",
    "from nnet_core import *;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only run this cell to destroy active data in memory\n",
    "# First, set 'reset' to True to confirm\n",
    "\n",
    "reset = False; assert(reset)\n",
    "\n",
    "network_qtys_lst = []\n",
    "network_keep_lst = []\n",
    "network_eta_lst = []\n",
    "network_decay_lst = []\n",
    "network_firstlayer_lst = []\n",
    "network_secondlayer_lst = []\n",
    "network_epochs_lst = []\n",
    "network_setsize_lst = []\n",
    "network_batchsize_lst = []\n",
    "network_effectiveness_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: 0%; 18.29 mins left.\n",
      "Completion: 1%; 95.46 mins left.\n",
      "Completion: 1%; 122.72 mins left.\n",
      "Completion: 2%; 203.71 mins left.\n",
      "Completion: 2%; 242.77 mins left.\n",
      "Completion: 3%; 203.75 mins left.\n",
      "Completion: 3%; 206.46 mins left.\n",
      "Completion: 4%; 186.23 mins left.\n",
      "Completion: 4%; 167.7 mins left.\n",
      "Completion: 5%; 169.52 mins left.\n",
      "Completion: 5%; 191.04 mins left.\n",
      "Completion: 6%; 178.37 mins left.\n",
      "Completion: 6%; 174.24 mins left.\n",
      "Completion: 7%; 163.7 mins left.\n",
      "Completion: 7%; 159.32 mins left.\n",
      "Completion: 8%; 184.98 mins left.\n",
      "Completion: 8%; 179.27 mins left.\n",
      "Completion: 9%; 177.25 mins left.\n",
      "Completion: 9%; 168.8 mins left.\n",
      "Completion: 10%; 166.46 mins left.\n",
      "Completion: 10%; 158.68 mins left.\n",
      "Completion: 11%; 153.4 mins left.\n",
      "Completion: 11%; 149.8 mins left.\n",
      "Completion: 12%; 144.78 mins left.\n",
      "Completion: 12%; 146.8 mins left.\n",
      "Completion: 13%; 146.23 mins left.\n",
      "Completion: 13%; 140.64 mins left.\n",
      "Completion: 14%; 135.01 mins left.\n",
      "Completion: 14%; 130.22 mins left.\n",
      "Completion: 15%; 130.59 mins left.\n",
      "Completion: 15%; 136.68 mins left.\n",
      "Completion: 16%; 138.76 mins left.\n",
      "Completion: 16%; 135.17 mins left.\n",
      "Completion: 17%; 138.2 mins left.\n",
      "Completion: 17%; 136.08 mins left.\n",
      "Completion: 18%; 132.84 mins left.\n",
      "Completion: 18%; 130.41 mins left.\n",
      "Completion: 19%; 133.71 mins left.\n",
      "Completion: 19%; 131.14 mins left.\n",
      "Encountered an error training last network.\n",
      "10 10 1.3 0.0004 10 0 2 739 8\n",
      "Aborting and restarting iteration.\n",
      "Completion: 20%; 138.1 mins left.\n",
      "Completion: 20%; 137.73 mins left.\n",
      "Completion: 21%; 135.13 mins left.\n",
      "Completion: 21%; 131.39 mins left.\n",
      "Completion: 22%; 130.87 mins left.\n",
      "Completion: 22%; 127.39 mins left.\n",
      "Completion: 23%; 124.01 mins left.\n",
      "Completion: 23%; 121.87 mins left.\n",
      "Completion: 24%; 118.76 mins left.\n",
      "Completion: 24%; 115.96 mins left.\n",
      "Completion: 25%; 113.7 mins left.\n",
      "Completion: 25%; 113.16 mins left.\n",
      "Completion: 26%; 118.98 mins left.\n",
      "Completion: 26%; 117.55 mins left.\n",
      "Completion: 27%; 114.7 mins left.\n",
      "Completion: 27%; 115.3 mins left.\n",
      "Completion: 28%; 112.95 mins left.\n",
      "Completion: 28%; 110.58 mins left.\n",
      "Completion: 28%; 109.23 mins left.\n",
      "Completion: 29%; 107.45 mins left.\n",
      "Completion: 30%; 105.89 mins left.\n",
      "Completion: 30%; 104.13 mins left.\n",
      "Completion: 31%; 105.07 mins left.\n",
      "Completion: 31%; 103.3 mins left.\n",
      "Completion: 32%; 101.64 mins left.\n",
      "Completion: 32%; 99.43 mins left.\n",
      "Completion: 33%; 101.14 mins left.\n",
      "Completion: 33%; 101.3 mins left.\n",
      "Completion: 34%; 99.22 mins left.\n",
      "Completion: 34%; 98.8 mins left.\n",
      "Completion: 35%; 100.98 mins left.\n",
      "Completion: 35%; 99.13 mins left.\n",
      "Completion: 36%; 97.41 mins left.\n",
      "Completion: 36%; 95.5 mins left.\n",
      "Completion: 37%; 94.23 mins left.\n",
      "Completion: 37%; 96.68 mins left.\n",
      "Completion: 38%; 95.36 mins left.\n",
      "Completion: 38%; 94.59 mins left.\n",
      "Completion: 39%; 94.91 mins left.\n",
      "Completion: 39%; 95.44 mins left.\n",
      "Completion: 40%; 96.94 mins left.\n",
      "Completion: 40%; 98.66 mins left.\n",
      "Completion: 41%; 97.0 mins left.\n",
      "Completion: 41%; 98.0 mins left.\n",
      "Completion: 42%; 97.36 mins left.\n",
      "Completion: 42%; 97.62 mins left.\n",
      "Completion: 43%; 96.67 mins left.\n",
      "Completion: 43%; 96.38 mins left.\n",
      "Completion: 44%; 95.54 mins left.\n",
      "Completion: 44%; 93.94 mins left.\n",
      "Completion: 45%; 92.41 mins left.\n",
      "Completion: 45%; 92.13 mins left.\n",
      "Completion: 46%; 90.32 mins left.\n",
      "Completion: 46%; 89.31 mins left.\n",
      "Completion: 47%; 88.21 mins left.\n",
      "Completion: 47%; 88.25 mins left.\n",
      "Completion: 48%; 87.04 mins left.\n",
      "Completion: 48%; 85.63 mins left.\n",
      "Completion: 49%; 84.21 mins left.\n",
      "Completion: 49%; 82.85 mins left.\n",
      "Completion: 50%; 83.6 mins left.\n",
      "Completion: 50%; 82.31 mins left.\n",
      "Completion: 51%; 81.13 mins left.\n",
      "Completion: 51%; 79.86 mins left.\n",
      "Completion: 52%; 79.66 mins left.\n",
      "Completion: 52%; 78.19 mins left.\n",
      "Completion: 53%; 76.78 mins left.\n",
      "Completion: 53%; 76.66 mins left.\n",
      "Completion: 54%; 75.83 mins left.\n",
      "Completion: 54%; 74.42 mins left.\n",
      "Completion: 55%; 73.73 mins left.\n",
      "Completion: 55%; 72.97 mins left.\n",
      "Completion: 56%; 72.63 mins left.\n",
      "Completion: 56%; 71.31 mins left.\n",
      "Completion: 56%; 70.01 mins left.\n",
      "Completion: 57%; 69.98 mins left.\n",
      "Completion: 57%; 68.71 mins left.\n",
      "Completion: 58%; 67.45 mins left.\n",
      "Completion: 59%; 67.45 mins left.\n",
      "Completion: 59%; 66.98 mins left.\n",
      "Completion: 60%; 66.27 mins left.\n",
      "Completion: 60%; 66.12 mins left.\n",
      "Completion: 61%; 64.81 mins left.\n",
      "Completion: 61%; 63.94 mins left.\n",
      "Completion: 62%; 63.39 mins left.\n",
      "Completion: 62%; 62.17 mins left.\n",
      "Completion: 63%; 61.72 mins left.\n",
      "Completion: 63%; 60.87 mins left.\n",
      "Completion: 64%; 59.63 mins left.\n",
      "Completion: 64%; 58.83 mins left.\n",
      "Completion: 65%; 57.58 mins left.\n",
      "Completion: 65%; 56.78 mins left.\n",
      "Completion: 66%; 56.13 mins left.\n",
      "Completion: 66%; 55.3 mins left.\n",
      "Completion: 67%; 54.38 mins left.\n",
      "Completion: 67%; 53.18 mins left.\n",
      "Completion: 68%; 53.21 mins left.\n",
      "Completion: 68%; 52.19 mins left.\n",
      "Completion: 69%; 51.7 mins left.\n",
      "Completion: 69%; 50.96 mins left.\n",
      "Completion: 70%; 49.9 mins left.\n",
      "Completion: 70%; 49.99 mins left.\n",
      "Completion: 71%; 49.13 mins left.\n",
      "Completion: 71%; 48.75 mins left.\n",
      "Completion: 72%; 47.77 mins left.\n",
      "Encountered an error training last network.\n",
      "5 4 1.4000000000000001 0.0007 10 0 3 639 4\n",
      "Aborting and restarting iteration.\n",
      "Completion: 72%; 46.63 mins left.\n",
      "Completion: 73%; 45.77 mins left.\n",
      "Completion: 73%; 44.77 mins left.\n",
      "Completion: 74%; 44.3 mins left.\n",
      "Completion: 74%; 43.29 mins left.\n",
      "Completion: 75%; 42.19 mins left.\n",
      "Completion: 75%; 41.11 mins left.\n",
      "Completion: 76%; 40.4 mins left.\n",
      "Completion: 76%; 39.32 mins left.\n",
      "Encountered an error training last network.\n",
      "2 2 0.8 0.0005 10 0 3 488 3\n",
      "Aborting and restarting iteration.\n",
      "Completion: 77%; 38.39 mins left.\n",
      "Completion: 77%; 37.65 mins left.\n",
      "Completion: 78%; 36.85 mins left.\n",
      "Completion: 78%; 35.8 mins left.\n",
      "Completion: 79%; 34.77 mins left.\n",
      "Completion: 79%; 33.76 mins left.\n",
      "Completion: 80%; 32.8 mins left.\n",
      "Completion: 80%; 32.29 mins left.\n",
      "Completion: 81%; 31.28 mins left.\n",
      "Completion: 81%; 30.46 mins left.\n",
      "Completion: 82%; 29.47 mins left.\n",
      "Encountered an error training last network.\n",
      "6 6 1.4000000000000001 0.0 10 0 9 966 4\n",
      "Aborting and restarting iteration.\n",
      "Completion: 82%; 28.85 mins left.\n",
      "Completion: 83%; 28.25 mins left.\n",
      "Completion: 83%; 27.64 mins left.\n",
      "Completion: 84%; 26.79 mins left.\n",
      "Completion: 84%; 25.82 mins left.\n",
      "Completion: 85%; 24.98 mins left.\n",
      "Completion: 85%; 24.06 mins left.\n",
      "Completion: 86%; 23.14 mins left.\n",
      "Completion: 86%; 22.42 mins left.\n",
      "Completion: 87%; 21.62 mins left.\n",
      "Completion: 87%; 20.68 mins left.\n",
      "Completion: 88%; 19.81 mins left.\n",
      "Completion: 88%; 18.99 mins left.\n",
      "Completion: 89%; 18.3 mins left.\n",
      "Completion: 89%; 17.46 mins left.\n",
      "Completion: 90%; 16.61 mins left.\n",
      "Completion: 90%; 15.8 mins left.\n",
      "Completion: 91%; 14.94 mins left.\n",
      "Completion: 91%; 14.06 mins left.\n",
      "Completion: 92%; 13.49 mins left.\n",
      "Completion: 92%; 12.69 mins left.\n",
      "Completion: 93%; 11.85 mins left.\n",
      "Completion: 93%; 10.97 mins left.\n",
      "Completion: 94%; 10.12 mins left.\n",
      "Completion: 94%; 9.24 mins left.\n",
      "Completion: 95%; 8.38 mins left.\n",
      "Completion: 95%; 7.6 mins left.\n",
      "Completion: 96%; 6.73 mins left.\n",
      "Completion: 96%; 5.91 mins left.\n",
      "Completion: 97%; 5.11 mins left.\n",
      "Completion: 97%; 4.24 mins left.\n",
      "Completion: 98%; 3.41 mins left.\n",
      "Completion: 98%; 2.56 mins left.\n",
      "Completion: 99%; 1.7 mins left.\n",
      "Completion: 99%; 0.85 mins left.\n",
      "Completion: 100%; 0.0 mins left.\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "num_to_generate = 100\n",
    "_, test_set = load_data(400, 2, 500)\n",
    "\n",
    "start_time = time.time()\n",
    "time_elapsed_secs = lambda: time.time() - start_time\n",
    "\n",
    "i = 0\n",
    "while i < num_to_generate: \n",
    "    networkQty = random.randint(1, 15);\n",
    "    networkKeep = random.randint(1, networkQty);\n",
    "    networkEta = 0.1 * float(random.randint(5, 15));\n",
    "    networkDecay = 0.0001 * float(random.randint(0, 10));\n",
    "    firstLayer = random.randint(5, 30);\n",
    "    secondLayer = 0;\n",
    "    epochs = random.randint(1, 15);\n",
    "    setSize = random.randint(100, 1000);\n",
    "    batchSize = random.randint(1, 10);\n",
    "    \n",
    "    netw = []\n",
    "    try:\n",
    "        netw = nnet_train_new(networkQty, networkKeep, networkEta, networkDecay, \n",
    "                              firstLayer, secondLayer, epochs, setSize, batchSize, 500)\n",
    "    except: \n",
    "        print(\"Encountered an unknown error training last network.\")\n",
    "        print(networkQty, networkKeep, networkEta, networkDecay, firstLayer, secondLayer, epochs, setSize, batchSize)\n",
    "        print(\"Aborting and restarting iteration.\")\n",
    "        continue\n",
    "    \n",
    "    network_qtys_lst.append(networkQty)\n",
    "    network_keep_lst.append(networkKeep)\n",
    "    network_eta_lst.append(networkEta)\n",
    "    network_decay_lst.append(networkDecay)\n",
    "    network_firstlayer_lst.append(firstLayer)\n",
    "    network_secondlayer_lst.append(secondLayer)\n",
    "    network_epochs_lst.append(epochs)\n",
    "    network_setsize_lst.append(setSize)\n",
    "    network_batchsize_lst.append(batchSize)\n",
    "    network_effectiveness_lst.append(nnet_evaluate_multiple(netw, test_set)[2])\n",
    "\n",
    "    time_remaining = (time_elapsed_secs() / float(i + 1)) * float(num_to_generate - (i + 1))\n",
    "    time_remaining = time_remaining / 60\n",
    "    print(\"Completion: \" + str(int((float(i+1) / float(num_to_generate)) * 100.0)) +\"%; \" \n",
    "          + str(float(int(time_remaining*100))/100.0) + \" mins left.\")\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Learning Epochs': [1, 10, 6, 5, 8, 8, 15, 10, 13, 10, 5, 12, 9, 8, 12, 2, 15, 5, 7, 7, 2, 13, 4, 15, 6, 12, 11, 13, 14, 9, 15, 4, 8, 4, 12, 14, 14, 11, 10, 3, 9, 2, 9, 8, 14, 13, 3, 15, 8, 8, 2, 6, 8, 14, 13, 8, 15, 8, 11, 14, 8, 9, 10, 5, 14, 9, 10, 15, 8, 11, 1, 13, 7, 14, 11, 12, 7, 6, 4, 12, 6, 11, 8, 6, 14, 1, 2, 13, 8, 12, 11, 5, 4, 6, 8, 3, 6, 5, 6, 11, 1, 7, 12, 13, 7, 1, 7, 2, 10, 15, 13, 5, 15, 6, 10, 13, 2, 11, 8, 9, 14, 3, 13, 8, 10, 7, 10, 1, 1, 4, 14, 7, 9, 14, 8, 1, 9, 8, 2, 15, 8, 3, 3, 11, 7, 2, 4, 3, 1, 1, 12, 15, 6, 1, 15, 3, 4, 9, 9, 5, 8, 7, 13, 14, 3, 8, 5, 2, 11, 11, 2, 1, 6, 5, 11, 3, 12, 7, 15, 14, 11, 5, 13, 10, 7, 5, 13, 15, 2, 7, 11, 1, 14, 9, 9, 10, 11, 7, 2, 14, 5, 2, 8, 10, 9, 1, 8, 7, 2, 7, 12, 14, 14, 2, 9, 14, 3, 10, 10, 15, 9, 8, 11, 8, 3, 6, 8, 1, 15, 3, 15, 11, 5, 9, 1, 12, 5, 7, 12, 5, 14, 8, 15, 3, 11, 11, 7, 8, 4, 1, 4, 12, 5, 14, 13, 7, 1, 2, 12, 8, 10, 1, 5, 1, 13, 13, 12, 15, 6, 11, 13, 4, 14, 5, 1, 7, 7, 7, 13, 9, 6, 6, 1, 14, 15, 7, 4, 4, 1, 5, 15, 1, 9, 8, 11, 10, 4, 13, 6, 3], 'Effectiveness': [0.232, 0.674, 0.704, 0.62, 0.746, 0.75, 0.236, 0.382, 0.528, 0.742, 0.368, 0.804, 0.78, 0.604, 0.608, 0.428, 0.868, 0.086, 0.846, 0.47, 0.35, 0.674, 0.488, 0.66, 0.826, 0.854, 0.284, 0.624, 0.504, 0.582, 0.506, 0.44, 0.7, 0.712, 0.76, 0.6, 0.474, 0.53, 0.526, 0.534, 0.884, 0.31, 0.812, 0.424, 0.592, 0.548, 0.35, 0.41, 0.59, 0.676, 0.432, 0.714, 0.678, 0.628, 0.228, 0.604, 0.844, 0.526, 0.758, 0.602, 0.512, 0.33, 0.666, 0.452, 0.686, 0.742, 0.364, 0.678, 0.204, 0.492, 0.384, 0.502, 0.796, 0.528, 0.758, 0.376, 0.78, 0.82, 0.344, 0.862, 0.766, 0.354, 0.802, 0.256, 0.654, 0.386, 0.328, 0.468, 0.7, 0.814, 0.632, 0.608, 0.792, 0.754, 0.684, 0.55, 0.586, 0.514, 0.684, 0.496, 0.35, 0.662, 0.794, 0.86, 0.658, 0.236, 0.832, 0.422, 0.22, 0.65, 0.834, 0.508, 0.698, 0.554, 0.688, 0.89, 0.802, 0.486, 0.644, 0.646, 0.228, 0.56, 0.338, 0.722, 0.69, 0.844, 0.408, 0.06, 0.368, 0.734, 0.678, 0.564, 0.394, 0.526, 0.37, 0.492, 0.462, 0.704, 0.688, 0.796, 0.504, 0.472, 0.252, 0.738, 0.242, 0.364, 0.472, 0.21, 0.416, 0.446, 0.734, 0.796, 0.626, 0.074, 0.524, 0.462, 0.324, 0.628, 0.584, 0.45, 0.51, 0.63, 0.324, 0.622, 0.362, 0.686, 0.82, 0.558, 0.606, 0.838, 0.61, 0.242, 0.422, 0.584, 0.848, 0.744, 0.398, 0.688, 0.756, 0.734, 0.856, 0.736, 0.728, 0.712, 0.486, 0.84, 0.78, 0.444, 0.656, 0.566, 0.552, 0.414, 0.696, 0.714, 0.852, 0.658, 0.554, 0.57, 0.752, 0.806, 0.626, 0.596, 0.49, 0.73, 0.406, 0.338, 0.61, 0.55, 0.48, 0.84, 0.54, 0.65, 0.532, 0.29, 0.668, 0.278, 0.414, 0.9, 0.794, 0.748, 0.8, 0.398, 0.64, 0.812, 0.42, 0.618, 0.764, 0.144, 0.406, 0.32, 0.534, 0.704, 0.82, 0.808, 0.344, 0.782, 0.406, 0.864, 0.47, 0.514, 0.704, 0.634, 0.8, 0.434, 0.324, 0.466, 0.5, 0.862, 0.442, 0.298, 0.45, 0.77, 0.264, 0.284, 0.576, 0.494, 0.216, 0.362, 0.454, 0.388, 0.716, 0.198, 0.704, 0.116, 0.79, 0.732, 0.8, 0.724, 0.328, 0.458, 0.668, 0.278, 0.636, 0.69, 0.342, 0.8, 0.57, 0.87, 0.438, 0.536, 0.796, 0.566, 0.342, 0.92, 0.654, 0.546, 0.56, 0.796, 0.684, 0.408, 0.764, 0.67, 0.84, 0.852, 0.468, 0.734, 0.726, 0.696, 0.348, 0.518], 'First Layer Nodes': [29, 26, 21, 21, 28, 9, 13, 25, 8, 17, 6, 18, 19, 21, 29, 30, 29, 19, 25, 28, 9, 16, 12, 23, 19, 25, 28, 6, 11, 8, 16, 9, 15, 21, 22, 27, 12, 7, 18, 18, 24, 12, 28, 21, 7, 23, 15, 27, 23, 14, 28, 23, 26, 8, 5, 11, 16, 7, 26, 28, 8, 6, 27, 20, 28, 23, 15, 17, 24, 17, 29, 6, 20, 30, 19, 19, 11, 28, 11, 27, 15, 5, 19, 29, 19, 21, 14, 12, 26, 24, 28, 11, 15, 23, 30, 15, 8, 22, 23, 15, 16, 15, 26, 25, 23, 11, 14, 9, 11, 17, 24, 19, 19, 13, 29, 18, 29, 9, 18, 12, 8, 24, 29, 23, 20, 27, 14, 6, 15, 24, 9, 5, 12, 17, 11, 16, 13, 6, 30, 16, 11, 11, 24, 19, 8, 13, 21, 6, 30, 28, 24, 19, 28, 26, 8, 19, 17, 28, 22, 11, 18, 7, 9, 14, 15, 9, 24, 28, 13, 16, 13, 9, 20, 29, 15, 21, 23, 25, 27, 9, 13, 29, 6, 12, 7, 27, 26, 18, 13, 25, 19, 12, 23, 13, 28, 18, 13, 30, 30, 25, 14, 29, 14, 27, 8, 22, 6, 5, 15, 29, 7, 14, 23, 7, 23, 22, 14, 26, 26, 17, 8, 17, 22, 20, 29, 14, 18, 11, 9, 17, 5, 14, 18, 18, 28, 13, 18, 29, 7, 19, 7, 28, 23, 12, 18, 12, 13, 17, 18, 9, 30, 11, 7, 7, 27, 5, 23, 25, 14, 24, 7, 19, 19, 6, 23, 11, 17, 20, 24, 26, 27, 14, 5, 7, 29, 19, 19, 29, 5, 7, 29, 9, 20, 22, 17, 5, 30, 16, 17, 16, 23, 29, 19, 18, 18, 27, 30, 25, 6, 18], 'Net Quantity': [14, 12, 11, 10, 5, 8, 1, 2, 3, 5, 14, 14, 15, 8, 2, 3, 10, 2, 14, 13, 2, 15, 6, 8, 10, 10, 5, 4, 7, 8, 2, 13, 7, 15, 7, 12, 15, 5, 2, 10, 14, 3, 13, 3, 3, 1, 4, 5, 7, 4, 9, 9, 4, 9, 3, 6, 3, 12, 10, 6, 11, 13, 3, 10, 12, 7, 2, 13, 1, 4, 11, 8, 6, 12, 9, 2, 15, 8, 10, 6, 14, 4, 12, 12, 14, 11, 5, 1, 6, 5, 14, 12, 12, 14, 12, 15, 4, 15, 2, 3, 7, 11, 4, 12, 14, 10, 13, 9, 2, 8, 11, 4, 5, 2, 4, 13, 14, 14, 3, 8, 1, 6, 2, 3, 6, 9, 1, 4, 5, 13, 12, 13, 2, 7, 7, 15, 5, 10, 9, 9, 10, 12, 2, 7, 2, 2, 10, 3, 11, 12, 5, 12, 6, 4, 12, 4, 2, 7, 2, 14, 5, 13, 4, 2, 1, 14, 13, 2, 8, 15, 11, 11, 3, 5, 12, 10, 12, 14, 11, 11, 14, 4, 11, 12, 13, 11, 7, 8, 10, 2, 15, 1, 8, 7, 14, 8, 4, 2, 7, 12, 10, 14, 7, 11, 2, 8, 12, 10, 4, 10, 4, 9, 2, 10, 13, 3, 6, 12, 15, 4, 11, 2, 14, 11, 6, 12, 8, 10, 9, 1, 5, 7, 10, 5, 4, 14, 12, 11, 10, 11, 12, 7, 9, 9, 2, 4, 7, 13, 12, 11, 3, 5, 1, 3, 5, 9, 7, 2, 1, 3, 10, 9, 12, 7, 13, 15, 14, 3, 3, 5, 2, 11, 7, 11, 6, 5, 11, 13, 3, 7, 10, 11, 15, 13, 13, 10, 13, 13, 15, 6, 12, 9, 9, 15, 1, 14, 15, 4, 4, 1], 'Second Layer Nodes': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Net Keep Qty': [1, 1, 5, 5, 1, 7, 1, 1, 3, 4, 4, 2, 6, 2, 1, 1, 2, 2, 7, 6, 1, 15, 3, 3, 10, 8, 1, 4, 6, 6, 1, 9, 5, 7, 6, 3, 1, 5, 2, 1, 14, 1, 2, 1, 2, 1, 2, 3, 3, 3, 6, 2, 4, 7, 1, 2, 3, 9, 2, 1, 2, 1, 3, 3, 6, 6, 2, 1, 1, 1, 5, 8, 6, 4, 8, 2, 7, 3, 4, 6, 5, 1, 6, 1, 2, 6, 4, 1, 2, 2, 9, 4, 4, 8, 2, 1, 2, 7, 2, 1, 2, 3, 3, 9, 5, 4, 9, 1, 1, 3, 5, 4, 5, 2, 4, 8, 7, 7, 3, 6, 1, 1, 1, 3, 1, 9, 1, 2, 5, 7, 10, 8, 1, 1, 3, 9, 3, 5, 1, 4, 2, 10, 1, 7, 1, 2, 10, 1, 3, 3, 4, 5, 2, 3, 4, 1, 1, 7, 1, 14, 4, 4, 1, 2, 1, 9, 11, 2, 4, 5, 10, 1, 1, 2, 8, 7, 8, 5, 11, 7, 12, 2, 10, 11, 1, 9, 3, 1, 10, 1, 9, 1, 8, 5, 6, 8, 2, 1, 2, 7, 8, 4, 7, 8, 1, 2, 4, 4, 1, 7, 2, 2, 2, 4, 2, 2, 6, 10, 15, 2, 8, 1, 13, 10, 6, 6, 8, 2, 3, 1, 5, 2, 9, 5, 2, 10, 8, 10, 2, 6, 4, 1, 2, 2, 2, 1, 5, 12, 9, 10, 2, 5, 1, 1, 2, 3, 7, 2, 1, 1, 5, 1, 3, 5, 13, 10, 12, 3, 3, 1, 1, 10, 5, 6, 1, 5, 1, 4, 2, 7, 10, 6, 8, 8, 2, 5, 7, 13, 9, 5, 4, 8, 5, 9, 1, 5, 10, 1, 3, 1], 'Weight Decay Rate': [0.0002, 0.00030000000000000003, 0.0, 0.0009000000000000001, 0.0004, 0.0009000000000000001, 0.0002, 0.0002, 0.0, 0.0006000000000000001, 0.0005, 0.001, 0.0007, 0.0008, 0.0, 0.001, 0.0009000000000000001, 0.0, 0.0, 0.0007, 0.001, 0.0007, 0.0009000000000000001, 0.001, 0.0004, 0.0002, 0.0007, 0.0007, 0.0005, 0.0005, 0.0, 0.0001, 0.00030000000000000003, 0.0006000000000000001, 0.0001, 0.0009000000000000001, 0.00030000000000000003, 0.0002, 0.0008, 0.00030000000000000003, 0.0, 0.0007, 0.0004, 0.0004, 0.0007, 0.0007, 0.00030000000000000003, 0.0004, 0.0006000000000000001, 0.0006000000000000001, 0.0008, 0.00030000000000000003, 0.0009000000000000001, 0.0005, 0.0004, 0.001, 0.001, 0.0005, 0.00030000000000000003, 0.0009000000000000001, 0.0006000000000000001, 0.0009000000000000001, 0.0, 0.0007, 0.0, 0.0005, 0.0, 0.0009000000000000001, 0.0004, 0.0007, 0.0007, 0.0001, 0.0006000000000000001, 0.0002, 0.0002, 0.00030000000000000003, 0.0006000000000000001, 0.00030000000000000003, 0.0002, 0.0005, 0.0007, 0.0005, 0.001, 0.0006000000000000001, 0.0005, 0.0007, 0.0001, 0.0007, 0.0, 0.0007, 0.0006000000000000001, 0.0006000000000000001, 0.0009000000000000001, 0.0007, 0.0005, 0.00030000000000000003, 0.0007, 0.0007, 0.0006000000000000001, 0.0, 0.0009000000000000001, 0.0004, 0.00030000000000000003, 0.0004, 0.0002, 0.0008, 0.0008, 0.0008, 0.0006000000000000001, 0.0009000000000000001, 0.0007, 0.001, 0.0, 0.0009000000000000001, 0.0008, 0.0002, 0.00030000000000000003, 0.0005, 0.00030000000000000003, 0.0, 0.0007, 0.0006000000000000001, 0.0005, 0.001, 0.0007, 0.0002, 0.00030000000000000003, 0.001, 0.0004, 0.0002, 0.0006000000000000001, 0.0, 0.0007, 0.0001, 0.00030000000000000003, 0.0, 0.001, 0.001, 0.0006000000000000001, 0.0, 0.0004, 0.0009000000000000001, 0.0, 0.0002, 0.0004, 0.0004, 0.0, 0.0, 0.0006000000000000001, 0.0006000000000000001, 0.0001, 0.0009000000000000001, 0.0008, 0.0004, 0.001, 0.0, 0.00030000000000000003, 0.0006000000000000001, 0.0004, 0.0005, 0.0009000000000000001, 0.0009000000000000001, 0.00030000000000000003, 0.0004, 0.0, 0.001, 0.0005, 0.0006000000000000001, 0.0008, 0.0005, 0.0005, 0.0, 0.001, 0.0001, 0.00030000000000000003, 0.0009000000000000001, 0.001, 0.0004, 0.0004, 0.0009000000000000001, 0.001, 0.0002, 0.0009000000000000001, 0.0007, 0.0001, 0.0008, 0.0001, 0.0, 0.00030000000000000003, 0.00030000000000000003, 0.00030000000000000003, 0.0008, 0.0005, 0.001, 0.0001, 0.0006000000000000001, 0.001, 0.00030000000000000003, 0.00030000000000000003, 0.0001, 0.0008, 0.0004, 0.0006000000000000001, 0.0, 0.00030000000000000003, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0006000000000000001, 0.0, 0.0005, 0.0004, 0.0006000000000000001, 0.00030000000000000003, 0.0004, 0.0007, 0.0005, 0.0001, 0.0, 0.0007, 0.001, 0.0009000000000000001, 0.0005, 0.0001, 0.0006000000000000001, 0.0001, 0.0005, 0.0009000000000000001, 0.0007, 0.0002, 0.0007, 0.0001, 0.0002, 0.0009000000000000001, 0.0007, 0.0009000000000000001, 0.0002, 0.0007, 0.00030000000000000003, 0.00030000000000000003, 0.00030000000000000003, 0.0009000000000000001, 0.0005, 0.0004, 0.0005, 0.001, 0.0001, 0.0007, 0.001, 0.0001, 0.0, 0.0001, 0.0006000000000000001, 0.0009000000000000001, 0.00030000000000000003, 0.0, 0.0005, 0.0006000000000000001, 0.0005, 0.001, 0.0001, 0.0006000000000000001, 0.00030000000000000003, 0.001, 0.0, 0.0002, 0.0005, 0.0004, 0.0001, 0.00030000000000000003, 0.0001, 0.00030000000000000003, 0.0005, 0.0002, 0.0009000000000000001, 0.0009000000000000001, 0.0004, 0.00030000000000000003, 0.0009000000000000001, 0.00030000000000000003, 0.0009000000000000001, 0.0009000000000000001, 0.0005, 0.0007, 0.0008, 0.0001, 0.0008, 0.0004, 0.0001, 0.0001, 0.0005, 0.0005, 0.0008, 0.0001, 0.00030000000000000003, 0.0004, 0.0006000000000000001, 0.00030000000000000003, 0.0008], 'Learning Rate': [0.5, 1.1, 1.4000000000000001, 1.0, 1.1, 1.5, 0.5, 0.9, 1.2000000000000002, 0.9, 0.5, 1.0, 0.7000000000000001, 1.0, 1.2000000000000002, 1.4000000000000001, 1.0, 0.7000000000000001, 0.7000000000000001, 0.5, 0.9, 0.9, 0.8, 0.6000000000000001, 1.5, 1.1, 0.5, 0.6000000000000001, 1.0, 1.1, 1.4000000000000001, 0.6000000000000001, 0.8, 1.2000000000000002, 1.1, 0.5, 1.3, 0.5, 0.8, 0.7000000000000001, 0.7000000000000001, 1.1, 1.0, 1.2000000000000002, 0.6000000000000001, 1.0, 0.7000000000000001, 0.7000000000000001, 0.7000000000000001, 0.9, 1.4000000000000001, 0.8, 1.2000000000000002, 1.4000000000000001, 1.2000000000000002, 0.8, 1.1, 1.2000000000000002, 1.4000000000000001, 1.2000000000000002, 1.1, 0.6000000000000001, 0.7000000000000001, 0.8, 0.5, 1.5, 1.2000000000000002, 1.1, 0.5, 0.5, 1.1, 1.1, 1.5, 0.7000000000000001, 0.9, 1.2000000000000002, 1.3, 1.3, 1.4000000000000001, 0.5, 0.8, 0.8, 0.9, 1.3, 1.4000000000000001, 0.9, 0.9, 1.3, 1.5, 1.2000000000000002, 0.8, 1.5, 0.7000000000000001, 0.6000000000000001, 1.1, 1.3, 0.9, 1.3, 1.2000000000000002, 0.5, 0.5, 0.5, 1.0, 0.6000000000000001, 0.6000000000000001, 1.4000000000000001, 1.4000000000000001, 0.8, 0.6000000000000001, 0.8, 1.3, 0.8, 0.9, 1.3, 0.5, 1.3, 1.5, 1.1, 0.8, 1.2000000000000002, 1.3, 0.6000000000000001, 0.5, 0.9, 1.4000000000000001, 0.5, 1.2000000000000002, 0.6000000000000001, 0.8, 0.9, 1.4000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 1.0, 0.5, 0.9, 1.2000000000000002, 1.0, 1.2000000000000002, 1.0, 0.8, 0.7000000000000001, 0.6000000000000001, 0.7000000000000001, 1.2000000000000002, 0.9, 1.0, 0.9, 0.5, 1.5, 0.5, 1.5, 1.3, 1.2000000000000002, 1.3, 0.8, 0.9, 1.4000000000000001, 0.8, 1.3, 0.9, 0.7000000000000001, 1.1, 0.6000000000000001, 0.8, 1.4000000000000001, 1.2000000000000002, 0.7000000000000001, 1.5, 1.2000000000000002, 1.2000000000000002, 0.6000000000000001, 0.9, 1.0, 0.9, 0.5, 1.1, 0.8, 1.3, 1.2000000000000002, 0.9, 1.3, 1.2000000000000002, 1.3, 0.7000000000000001, 1.3, 0.7000000000000001, 1.4000000000000001, 1.3, 0.7000000000000001, 1.1, 1.3, 1.1, 0.8, 1.2000000000000002, 0.6000000000000001, 1.4000000000000001, 1.2000000000000002, 1.2000000000000002, 0.5, 1.3, 0.9, 0.6000000000000001, 1.3, 0.9, 0.9, 1.0, 1.0, 1.1, 0.6000000000000001, 1.3, 1.5, 0.8, 1.1, 0.5, 0.5, 1.2000000000000002, 1.0, 1.5, 0.5, 0.6000000000000001, 1.2000000000000002, 0.6000000000000001, 1.0, 0.9, 1.4000000000000001, 0.5, 0.6000000000000001, 1.3, 0.8, 1.0, 1.0, 1.3, 1.5, 0.8, 0.5, 1.3, 1.1, 1.4000000000000001, 1.2000000000000002, 1.1, 1.3, 1.2000000000000002, 0.8, 1.0, 0.7000000000000001, 0.6000000000000001, 0.8, 0.6000000000000001, 1.4000000000000001, 1.2000000000000002, 1.0, 0.5, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 1.5, 1.4000000000000001, 0.6000000000000001, 0.7000000000000001, 0.6000000000000001, 1.3, 0.8, 1.4000000000000001, 1.0, 1.5, 0.8, 1.2000000000000002, 0.9, 0.7000000000000001, 1.2000000000000002, 1.4000000000000001, 0.9, 1.3, 1.0, 1.4000000000000001, 1.5, 0.5, 0.7000000000000001, 0.5, 1.3, 0.6000000000000001, 0.9, 1.3, 0.5, 0.8, 0.8, 1.5, 1.0, 0.9, 1.0, 1.4000000000000001, 0.5, 0.5, 0.9, 0.9, 0.6000000000000001, 0.9, 1.3], 'Training Set Size': [232, 981, 539, 479, 736, 803, 294, 309, 750, 683, 401, 713, 977, 511, 344, 934, 618, 338, 850, 465, 872, 287, 561, 552, 529, 628, 136, 807, 178, 345, 341, 449, 430, 673, 288, 273, 452, 543, 734, 762, 883, 639, 939, 334, 696, 822, 749, 116, 367, 365, 480, 804, 243, 260, 341, 618, 650, 271, 659, 501, 406, 715, 757, 377, 366, 458, 256, 384, 148, 698, 113, 136, 577, 165, 564, 112, 929, 791, 235, 917, 675, 753, 532, 144, 415, 299, 148, 651, 878, 605, 144, 522, 623, 960, 586, 885, 432, 151, 544, 509, 382, 456, 805, 614, 971, 164, 548, 638, 207, 309, 650, 522, 371, 752, 642, 858, 870, 170, 257, 455, 302, 829, 895, 435, 955, 582, 371, 116, 863, 788, 522, 702, 705, 582, 353, 784, 346, 984, 973, 964, 508, 437, 388, 495, 115, 491, 353, 211, 309, 947, 589, 784, 698, 183, 269, 667, 861, 287, 879, 164, 254, 772, 170, 483, 393, 817, 844, 810, 421, 630, 243, 996, 130, 798, 963, 595, 124, 646, 371, 715, 773, 481, 687, 305, 893, 578, 605, 249, 503, 920, 287, 934, 178, 369, 529, 181, 214, 890, 910, 625, 229, 682, 187, 562, 247, 731, 810, 504, 706, 580, 920, 490, 178, 299, 719, 121, 381, 726, 310, 749, 917, 171, 103, 618, 299, 874, 546, 432, 209, 727, 472, 667, 712, 552, 233, 653, 215, 956, 348, 136, 878, 614, 674, 938, 117, 893, 320, 865, 268, 187, 383, 1000, 494, 590, 829, 704, 381, 550, 496, 416, 960, 176, 621, 110, 408, 404, 509, 755, 227, 616, 503, 177, 733, 920, 267, 613, 468, 981, 934, 472, 736, 322, 481, 968, 236, 651, 175, 595, 766, 322, 518, 576, 897, 859, 541, 593, 545, 743, 553, 382], 'Training Batch Size': [2, 8, 6, 8, 2, 8, 4, 4, 6, 4, 9, 2, 8, 8, 4, 7, 2, 9, 3, 10, 8, 8, 8, 8, 1, 5, 5, 6, 8, 2, 7, 10, 3, 10, 1, 5, 10, 6, 9, 2, 3, 7, 5, 8, 1, 5, 7, 10, 8, 5, 8, 6, 1, 6, 10, 3, 1, 9, 9, 10, 4, 10, 8, 8, 6, 7, 10, 1, 7, 10, 1, 4, 5, 5, 6, 9, 6, 2, 9, 2, 2, 4, 3, 9, 9, 2, 3, 3, 8, 1, 3, 10, 1, 7, 6, 5, 4, 5, 2, 4, 1, 3, 3, 3, 8, 7, 4, 1, 2, 5, 1, 7, 1, 6, 4, 1, 3, 5, 1, 6, 10, 3, 10, 3, 5, 2, 4, 5, 7, 7, 9, 8, 10, 7, 8, 5, 9, 10, 1, 5, 8, 8, 8, 3, 1, 4, 9, 5, 1, 5, 9, 4, 8, 9, 10, 4, 8, 5, 10, 7, 8, 7, 5, 6, 1, 7, 8, 9, 5, 3, 2, 10, 1, 5, 5, 3, 10, 9, 6, 9, 4, 1, 1, 8, 7, 2, 8, 5, 4, 4, 9, 7, 6, 1, 1, 2, 2, 9, 1, 9, 1, 7, 10, 9, 4, 8, 9, 6, 2, 4, 4, 7, 6, 5, 10, 9, 3, 2, 1, 7, 2, 3, 3, 3, 8, 10, 9, 10, 6, 6, 1, 3, 2, 1, 1, 10, 8, 5, 4, 3, 5, 7, 5, 10, 3, 9, 5, 2, 6, 2, 7, 2, 8, 10, 10, 1, 5, 6, 5, 6, 4, 10, 6, 4, 5, 5, 10, 9, 6, 9, 2, 9, 6, 9, 2, 1, 5, 4, 7, 6, 6, 6, 6, 2, 2, 4, 4, 2, 6, 9, 7, 2, 2, 3, 3, 9, 6, 2, 8, 1]}\n"
     ]
    }
   ],
   "source": [
    "filename = \"testoutput.json\"\n",
    "\n",
    "output_data = {\"Net Quantity\":network_qtys_lst,\n",
    "              \"Net Keep Qty\":network_keep_lst,\n",
    "              \"Learning Rate\":network_eta_lst, \n",
    "              \"Weight Decay Rate\":network_decay_lst,\n",
    "              \"First Layer Nodes\":network_firstlayer_lst,\n",
    "              \"Second Layer Nodes\":network_secondlayer_lst,\n",
    "              \"Learning Epochs\":network_epochs_lst,\n",
    "              \"Training Set Size\":network_setsize_lst,\n",
    "              \"Training Batch Size\":network_batchsize_lst,\n",
    "              \"Effectiveness\":network_effectiveness_lst}\n",
    "output_data_backup = output_data\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "\n",
    "file = open(filename, 'ab+')\n",
    "pickle.dump(output_data, file)\n",
    "file.close()\n",
    "\n",
    "file = open(filename, 'rb')\n",
    "tmp = pickle.load(file)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netw = nnet_train_new(26, 13, 1.02, 0.000325, \n",
    "                              21, 0, 10, 699, 3, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(network_qtys_lst))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
